# Тестовое задание 2: Улучшение промптов для LLM и сравнение результатов

**Цель задания:**
Проверить навыки кандидата в оптимизации промптов для Large Language Models (LLM), включая анализ эффективности, улучшение и сравнение результатов. Задание моделирует реальную задачу тестировщика, где нужно повысить качество ответов модели через prompt engineering.

**Формат выполнения:**
- Выполните задание, используя любой доступный LLM (например, Grok, Qwen, Deepseek, ChatGPT или другие). Можно использовать сторонние сервисы (например, Hugging Face, OpenAI Playground) для тестирования.
- Документируйте процесс и результаты в текстовом файле (Markdown или TXT).

---

## Задание

### 1. Выбор и исходные промпты
Мы предоставляем **3 исходных промпта** для тестирования LLM. Выберите **один из них** (или все, если хотите, за бонусные баллы) и используйте его как основу. Каждый промпт предназначен для генерации ответа на конкретную задачу.

**Исходные промпты:**

1. **Промпт 1: Генерация креативного текста**
 "Напиши короткий рассказ о приключениях робота в будущем."

2. **Промпт 2: Анализ данных**
 "Проанализируй этот список чисел: 1, 3, 5, 7, 9. Найди среднее значение и медиану."

3. **Промпт 3: Техническая задача**
 "Объясни, как работает RAG (Retrieval-Augmented Generation) в LLM."

Для выбранного промпта:
- Введите его в LLM и запишите исходный ответ модели.
- Оцените исходный ответ по критериям: корректность, релевантность, полнота, ясность (шкала 1-5).

---

### 2. Улучшение промпта
Улучшите выбранный промпт, чтобы повысить качество ответа модели. Вы можете расширять промпт, добавляя:
- Детали для уточнения (например, стиль, длина, ключевые элементы).
- Инструкции по структуре ответа (например, "Структура: введение, основная часть, заключение").
- Примеры (few-shot prompting).
- Ролевые инструкции (например, "Ты - эксперт в...").
- Ограничения или уточнения для избежания ошибок.

Можно использовать сторонние сервисы или инструменты для экспериментов (например, Prompt Engineering Guide, A/B-тестирование в разных моделях).

**Пример улучшения (для Промпта 1):**
Исходный: "Напиши короткий рассказ о приключениях робота в будущем."
Улучшенный: "Ты - писатель-фантаст. Напиши короткий рассказ (300-500 слов) о приключениях робота в дистопическом будущем 2050 года. Включи элементы: дружба с человеком, моральная дилемма и неожиданный поворот. Структура: введение, развитие, кульминация, развязка."

- Введите улучшенный промпт в ту же LLM и запишите новый ответ.
- Оцените новый ответ по тем же критериям (корректность, релевантность, полнота, ясность).

---

### 3. Сравнение и анализ
Сравните результаты до и после улучшения:
- **Сравнение ответов:** Опишите ключевые различия (например, длина, детализация, креативность).
- **Сравнение оценок:** Покажите изменения по критериям (например, таблицей).
- **Анализ:** Объясните, почему улучшения сработали (или нет). Укажите, что можно улучшить дальше.
- **Рекомендации:** Предложите общие советы по prompt engineering для подобных задач.

Запишите в формате:
- Исходный промпт и ответ.
- Улучшенный промпт и ответ.
- Сравнение: [описание различий].
- Оценки: [таблица или список].
- Анализ и рекомендации: [описание].

---

### 4. Бонусный пункт: Тестирование на нескольких моделях
Протестируйте улучшенный промпт на 2-3 разных моделях (например, Grok и Qwen) и сравните ответы. Опишите различия и выберите лучшую модель для этой задачи.

---

## Требования к результатам

- Документ в формате Markdown или TXT.
- Чёткая структура: выбранный промпт, исходные/улучшенные результаты, сравнение, анализ.
- Приложите скриншоты диалогов с моделями (если возможно) или процитируйте точные ответы.
- Укажите, какие модели и сервисы вы использовали.

---

## Критерии оценки

- Качество улучшения промпта (креативность, эффективность в повышении качества ответа).
- Глубина сравнения и анализа (обоснованность выводов).
- Чёткость и структурированность документации.
- (Бонус) Эксперименты с несколькими моделями и дополнительные insights.

---

